---
inFeed: true
hasPage: true
inNav: false
inLanguage: null
keywords: []
description: "Whenever people talk about computers taking jobs, rarely do they think of the CEO. I was reading about decentralized organizations like The DAO today, and it's pretty clever. Often times management is the biggest pain for employees and a ton of sources put disliking one's manager as the primary reason most employees leave. No manager, no disliking the manager. That makes sense to me. There are numerous reasons why it will be very hard to implement a manager/executive AI, but the much more fun idea is to think about if it were executed perfectly. "
datePublished: '2016-05-17T20:31:22.247Z'
dateModified: '2016-05-17T20:26:30.948Z'
title: ''
author: []
authors: []
publisher:
  name: null
  domain: null
  url: null
  favicon: null
starred: false
sourcePath: _posts/2016-05-17-ai-in-governance.md
url: ai-in-governance/index.html
_type: Article

---
Whenever people talk about computers taking jobs, rarely do they think of the CEO. I was reading about decentralized organizations like [The DAO][0] today, and it's pretty clever. Often times management is the biggest pain for employees and a ton of sources put disliking one's manager as the primary reason most employees leave. No manager, no disliking the manager. That makes sense to me. There are numerous reasons why it will be very hard to implement a manager/executive AI, but the much more fun idea is to think about if it were executed perfectly. 

## Benevolent Autocracy

For any number of reasons the best form of governance is the "benevolent autocracy." The primary driver for that is that communication is hard and grows in complexity much faster with more nodes (people). Having a single autocrat with absolute power drastically reduces the overhead of communication as the the autocrat need only communicate down and to everyone. I've always heard that the only problem with the benevolent autocracy is that they die (the implication being there's then a power vacuum filled with someone a bit less benevolent). AI doesn't have to die so the major problem with benevolent autocracy is gone. We would have to have some fear that the AI wasn't exactly benevolent in the way we imagined, but for the sake of argument let's just say we figured that out as well.

## Rational, self-interested, and well-informed

There's the huge underlying assumption with capitalism that everyone is rational, self-interested, and well-informed. This is a lot like using the [small-angle approximation][1] for the orbit of satellites, but some assumptions are necessary to make any initial guesses about the world and human behavior. First, rational - the in thing these days in behavioral economics is a concept called "bounded rationality." The books [Nudge][2] and [Misbehaving][3] talk a lot about the difference between _econs _and_humans. _Thaler points out that a lot of what humans do is neither rational nor reasonable. However, this AI that runs companies may be hyper-rational so all of those goofy irrational choices humans make, it could avoid entirely. The second assumption about people under capitalism is that people are self-interested. Some people try to help other people, which from a strictly economic standpoint is wasteful. Waste is inherently immoral because of finite resources, so to a strict, rational capitalist helping other people is immoral as well. People give gifts and waste all kinds of resources continuously, and that causes a pretty substantial deviation from the theoretical model of capitalism; our AI business leader, does not need such folly - it can be truly self-interested. Finally, there's the well-informed assumption. This works in tandem with self-interested and is in my belief where theoretical capitalism and people's misunderstanding of capitalism diverge. It is almost never in someone's best interest to hurt or offend others. Expending social reputation for short-term gain is normally a very dumb idea. Where people go wrong is they are not well-informed, leading them to be irrational about what is in their interests. By the nature of speed of computation vs human thought an AI business executive can truly be well informed. Maybe not with the technology of today, but eventually it could be plugged into all communication within the company and about the company in public. This massive amount of data could allow the company to always go in a direction the public wants in a way the employees also want. 

Basically, the AI business executive could become the ultimate CEO, perfectly translating public desires into actionable internal directives.

[0]: https://daohub.org/
[1]: https://en.wikipedia.org/wiki/Small-angle_approximation
[2]: http://www.amazon.com/Nudge-Improving-Decisions-Health-Happiness/dp/014311526X
[3]: http://www.amazon.com/Misbehaving-Behavioral-Economics-Richard-Thaler/dp/0393080943/ref=sr_1_1?s=books&ie=UTF8&qid=1463515853&sr=1-1&keywords=misbehaving