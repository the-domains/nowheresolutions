<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[Nowhere Solutions]]></title>
        <description><![CDATA[Nowhere Solutions]]></description>
        <link>https://thegrid.ai/nowheresolutions/</link>
        <generator>The Grid</generator>
        <lastBuildDate>Tue, 17 May 2016 20:31:45 GMT</lastBuildDate>
        <atom:link href="https://thegrid.ai/nowheresolutions/rss.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[AI in governance]]></title>
            <description><![CDATA[<p>Whenever people talk about computers taking jobs, rarely do they think of the CEO. I was reading about decentralized organizations like The DAO today, and it's pretty clever. Often times management is the biggest pain for employees and a ton of sources put disliking one's manager as the primary reason most employees leave. No manager, no disliking the manager. That makes sense to me. There are numerous reasons why it will be very hard to implement a manager/executive AI, but the much more fun idea is to think about if it were executed perfectly. </p>]]></description>
            <link>https://thegrid.ai/nowheresolutions/ai-in-governance/index.html</link>
            <guid isPermaLink="false">2f2e92bb-6817-4bd3-bd99-2f25178aa969</guid>
            <pubDate>Tue, 17 May 2016 20:31:22 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Machine Learning - Part 3]]></title>
            <description><![CDATA[<p>This came up so many times it made me sick, but overfitting is a huge challenge in machine learning. There's a pretty good reason, if you look back I talked about error. Well if you imagine any observation is made up of something we wanted to observe, and elements we did not want to observe, yet observed by mistake (error). Now it may not be known what we wanted to observe or how it relates to what we actually did observe, but that's okay. One mistake we can make, however, is to assume that our observation is entirely useful. When we do that, we have observed noise and interpreted it as signal. I said elements we observed by mistake because sometimes noise can actually be useful information, just not by our current observation. For example, if I wanted to determine the speed of a motor powering a saw in a saw mill and I decided I would use rough calculations based on computer vision from a feed of logs approaching the saw. Well I might find that it's sometimes hard to see the logs through the camera because too much sawdust is in the way, and I might consider that noise. However, if I was clever I might use the amount of the field of view obstructed by sawdust as my signal, and then it isn't noise at all. Just like quantum mechanics, it's all a matter of perspective. </p>]]></description>
            <link>https://thegrid.ai/nowheresolutions/machine-learning-part-3/index.html</link>
            <guid isPermaLink="false">9ca2e4cb-6fdb-4e47-9655-a1e3861b07d4</guid>
            <pubDate>Mon, 02 May 2016 04:35:19 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Machine Learning - part 2]]></title>
            <description><![CDATA[<p>Now I'm a pretty big fan of control systems which for some reason hasn't collided with machine learning to be absorbed into a general field of study. Basically, they are nearly the same. Anyway, what control theory teaches us is there's this thing called error, and that's what we learn from. People have all sorts of cute expressions to analogize this to life experience, but the point of the matter is: error is extremely important.</p>]]></description>
            <link>https://thegrid.ai/nowheresolutions/machine-learning-part-2/index.html</link>
            <guid isPermaLink="false">b6772743-c17e-4e03-9146-9f10b87e4106</guid>
            <pubDate>Mon, 25 Apr 2016 23:40:18 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Machine Learning - part 1]]></title>
            <description><![CDATA[<p>So it seems like at first what we learn from machine learning is: things are correlated. Crazytown I know, but yes there are things we want to know and those things are, in fact, often related to things we already know or can know. </p>]]></description>
            <link>https://thegrid.ai/nowheresolutions/machine-learning-part-1/index.html</link>
            <guid isPermaLink="false">800e5162-c70e-4961-abd7-392a35595b8d</guid>
            <pubDate>Mon, 25 Apr 2016 23:29:20 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Learning]]></title>
            <description><![CDATA[<p>So recently I started taking the Machine Learning NanoDegree from Udacity, and I think it's pretty cool. Unfortunately for me I've read a whole lot about machine learning (and learning in general) in the past so a lot of it feels like things I've heard over and over again. This, I guess, is the value of actually going to school for something, you have the confidence of having actually been certified to know something, even if the value of that certification is unreliable - at least it exists. Hence, I'm taking a nanodegree; that way I'll have some certification that I know some things and maybe then I can get a start and my projects will then speak for themselves.</p>]]></description>
            <link>https://thegrid.ai/nowheresolutions/learning/index.html</link>
            <guid isPermaLink="false">db6822d2-e247-43e2-87bb-396aa1d63586</guid>
            <pubDate>Mon, 25 Apr 2016 23:11:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[No title]]></title>
            <description><![CDATA[<p>Websites: Far from a solved problem. I love websites but it's so hard to make one. Mostly just because it's hard to maintain a website. I imagine the same problem exists for books and other large projects. Single Piece Flow is usually the best strategy for making something with as little waste as possible, but a large body of work that continues to expand for days or weeks is difficult to make "single piece".Â </p>]]></description>
            <link>https://thegrid.ai/nowheresolutions/cc8e05df-94f9-4750-baf0-a52df0b17464/index.html</link>
            <guid isPermaLink="false">cc8e05df-94f9-4750-baf0-a52df0b17464</guid>
            <pubDate>Mon, 11 Apr 2016 18:21:19 GMT</pubDate>
        </item>
    </channel>
</rss>